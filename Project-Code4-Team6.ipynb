{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"newTrainingDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set \n",
    "\n",
    "y = data.click\n",
    "X = data.iloc[:, 1:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set \n",
    "\n",
    "vali = pd.read_csv(\"newValidationDataset.csv\")\n",
    "X_test = vali.iloc[:, 1:49]\n",
    "y_true = vali.click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize decision tree \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "inner_cv = KFold(n_splits=5, shuffle=True)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "gs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
    "                 param_grid=[{'max_depth': [4, 6, 8, 10, None], 'criterion':['gini','entropy'], \n",
    "                              'min_samples_leaf':[1,2,3,4,5],\n",
    "                              'min_samples_split':[2,3,4,5]}],\n",
    "                  scoring='neg_log_loss',\n",
    "                  cv=inner_cv)\n",
    "gs = gs.fit(X,y)\n",
    "print(\"Optimal Parameter: \", gs.best_params_)\n",
    "print(\"Optimal Estimator: \", gs.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of DT \n",
    "\n",
    "import sklearn \n",
    "from sklearn.metrics import log_loss\n",
    "dt = DecisionTreeClassifier(max_depth=8, criterion='gini', min_samples_leaf = 5, random_state=0)\n",
    "\n",
    "y_pred = dt.fit(X, y).predict_proba(X_test)\n",
    "sklearn.metrics.log_loss(y_true, y_pred, normalize=True, sample_weight=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.195075728470081"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of Naive Baynes \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn \n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred2 = gnb.fit(X, y).predict_proba(X_test)\n",
    "\n",
    "sklearn.metrics.log_loss(y_true, y_pred2, normalize=True, sample_weight=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small sample of training and validation sets to run code faster \n",
    "\n",
    "train_X = X.sample(n=2000000)\n",
    "train_y = y.sample(n=2000000)\n",
    "vali_sample = vali.sample(n=1000000)\n",
    "X_sample = X_test.sample(n=1000000)\n",
    "y_sample = y_true.sample(n=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize SVM\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "op_sup = [{'kernel': ['rbf','linear','poly','sigmoid'], 'gamma': ['scale', 'auto'],\n",
    "                     'C': [1, 10, 100, 1000, 10000]}]\n",
    "\n",
    "sup = GridSearchCV(SVC(random_state=0,probability=True),\n",
    "                 op_sup,\n",
    "                  scoring='neg_log_loss')\n",
    "sup = sup.fit(train_X,train_y)\n",
    "print(\"Optimal Parameter: \", sup.best_params_)\n",
    "print(\"Optimal Estimator: \", sup.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45752086747900683"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of SVM\n",
    "\n",
    "from sklearn import svm\n",
    "import sklearn \n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "svc = svm.SVC(probability=True, C=100, gamma='scale', kernel='rbf', random_state=0)\n",
    "y_pred3 = svc.fit(train_X, train_y).predict_proba(X_sample)\n",
    "\n",
    "sklearn.metrics.log_loss(y_sample, y_pred3, normalize=True, sample_weight=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Parameter:  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Optimal Estimator:  DecisionTreeClassifier(criterion='entropy', max_depth=6, min_samples_leaf=3,\n",
      "                       random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# Fiting DT with the small sample  \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "gs_new = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
    "                 param_grid=[{'max_depth': [6, 8, 10, None], 'criterion':['gini','entropy'], \n",
    "                              'min_samples_leaf':[2,3,4],\n",
    "                              'min_samples_split':[2,3,4]}],\n",
    "                  scoring='neg_log_loss')\n",
    "gs_new = gs_new.fit(train_X,train_y)\n",
    "print(\"Optimal Parameter: \", gs_new.best_params_)\n",
    "print(\"Optimal Estimator: \", gs_new.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6011251125519442"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of DT with the samll sample \n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=6, criterion='entropy', min_samples_leaf = 4, random_state=0)\n",
    "y_pred5 = dt.fit(train_X, train_y).predict_proba(X_sample)\n",
    "\n",
    "sklearn.metrics.log_loss(y_sample, y_pred5, normalize=True, sample_weight=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize Neural Nets \n",
    "\n",
    "import numpy as np \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'solver': ['lbfgs','sgd', 'adam'], 'max_iter': [500,1000,1500], 'alpha': 10.0 ** -np.arange(1, 7), \n",
    "              'hidden_layer_sizes':np.arange(5, 12), 'activation': ['identity', 'logistic', 'tanh', 'relu']}\n",
    "\n",
    "net = GridSearchCV(MLPClassifier(random_state=1), parameters, n_jobs=-1,\n",
    "                  scoring='neg_log_loss')\n",
    "\n",
    "gs_net = net.fit(train_X, train_y)\n",
    "\n",
    "print(\"Optimal Estimator: \", gs_net.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45602347354500145"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of Neural Nets \n",
    "\n",
    "net_1 = MLPClassifier(alpha=0.1, hidden_layer_sizes=5, max_iter=500, random_state=1,solver='lbfgs')\n",
    "\n",
    "y_pred6 = net_1.fit(train_X, train_y).predict_proba(X_sample)\n",
    "\n",
    "sklearn.metrics.log_loss(y_sample, y_pred6, normalize=True, sample_weight=None, labels=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
